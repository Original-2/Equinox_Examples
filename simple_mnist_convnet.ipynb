{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Original-2/Equinox_Examples/blob/main/simple_mnist_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bbdTKGESjQY"
      },
      "source": [
        "# Equinox version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-8qSyuoS-9A",
        "outputId": "631ec1df-fd2d-4440-8e1e-86eab2ff0b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting equinox\n",
            "  Downloading equinox-0.5.3-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from equinox) (0.3.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->equinox) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->equinox) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->equinox) (4.1.1)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->equinox) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->equinox) (1.21.6)\n",
            "Installing collected packages: equinox\n",
            "Successfully installed equinox-0.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.2-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.7+cuda11.cudnn805)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.3-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 634 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.8)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.3 optax-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install equinox\n",
        "!pip3 install optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X9yb67y4SjC1"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "from tensorflow import keras\n",
        "import equinox as eqx\n",
        "import jax\n",
        "import optax\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSr8yrxnSvHr",
        "outputId": "07c9aab9-0d38-4031-a995-204a2403d254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "x_train = jnp.expand_dims(x_train, -1)\n",
        "x_test = jnp.expand_dims(x_test, -1)\n",
        "\n",
        "x_train = jnp.resize(jnp.array(x_train), (len(x_train),1,28,28,))\n",
        "x_test = jnp.resize(jnp.array(x_test), (len(x_test),1,28,28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HjoLMZ-JeUu8"
      },
      "outputs": [],
      "source": [
        "y_train = list(y_train)\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  temp = y_train[i]\n",
        "  y_train[i] = [0 for i in range(10)]\n",
        "  y_train[i][temp] = 1\n",
        "\n",
        "y_test = list(y_test)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  temp = y_test[i]\n",
        "  y_test[i] = [0 for i in range(10)]\n",
        "  y_test[i][temp] = 1\n",
        "\n",
        "y_train = jnp.array(y_train)\n",
        "y_test = jnp.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5h3RSV4BSv1o"
      },
      "outputs": [],
      "source": [
        "import equinox as eqx\n",
        "import jax\n",
        "import jax.example_libraries.stax as stax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "class ConvNet(eqx.Module):\n",
        "    conv: list\n",
        "    dense: eqx.nn.Linear\n",
        "    drop: eqx.nn.Dropout\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        key,\n",
        "    ):\n",
        "        key1, key2, key3 = jax.random.split(key, 3)\n",
        "\n",
        "        self.conv = [eqx.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=2, key=key1),\n",
        "                      eqx.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=2, key=key2),\n",
        "                      ]\n",
        "\n",
        "        self.dense = eqx.nn.Linear(4096, 10, key=key3)\n",
        "        self.drop = eqx.nn.Dropout()\n",
        "    def __call__(self, x, key, inference=False):\n",
        "        x = jax.nn.relu(self.conv[0](x))\n",
        "        x = eqx.nn.AvgPool2D((2,2),2)(x)\n",
        "\n",
        "        x = jax.nn.relu(self.conv[1](x))\n",
        "        x = eqx.nn.AvgPool2D((2,2),2)(x)\n",
        "\n",
        "        x = x.flatten()\n",
        "        x = self.drop(x, key=key)\n",
        "        x = self.dense(x)\n",
        "        return jax.nn.softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dI9IqB2CAaV_"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size=128,\n",
        "    learning_rate=0.001,\n",
        "    steps=60000//128,\n",
        "    val_steps=10000//128,\n",
        "    seed=5678,\n",
        "    epochs=15\n",
        "):\n",
        "    key = jax.random.PRNGKey(seed)\n",
        "    key, temp = jax.random.split(key, 2)\n",
        "    model = ConvNet(key=temp)\n",
        "\n",
        "    @eqx.filter_value_and_grad\n",
        "    def compute_loss(model, x, y, key):\n",
        "        predy = jax.vmap(model)(x, key=jnp.array(key))    \n",
        "        predy = jnp.clip(predy, 1e-7, 1 - 1e-7)\n",
        "        losses = jnp.sum(y * -jnp.log(predy), axis=-1, keepdims=False)\n",
        "        return jnp.mean(losses)\n",
        "\n",
        "    @eqx.filter_jit\n",
        "    def make_step(model, x, y, opt_state, key):\n",
        "        loss, grads = compute_loss(model, x, y, key)\n",
        "        updates, opt_state = optim.update(grads, opt_state)\n",
        "        model = eqx.apply_updates(model, updates)\n",
        "        return loss, model, opt_state\n",
        "\n",
        "    def compute_metrics(model, x, y, key):\n",
        "        predy = jax.vmap(model)(x, jnp.array(key), jnp.array([True for i in range(batch_size)]))    \n",
        "        predy = jnp.clip(predy, 1e-7, 1 - 1e-7)\n",
        "        losses = jnp.sum(y * -jnp.log(predy), axis=-1, keepdims=False)\n",
        "\n",
        "        accuracy = jnp.mean(jnp.argmax(predy, -1) == jnp.argmax(y, -1))\n",
        "        return jnp.mean(losses), accuracy\n",
        "\n",
        "    optim = optax.adam(learning_rate)\n",
        "    opt_state = optim.init(model)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        bar = trange(steps)\n",
        "        for i in bar:\n",
        "            bar.set_description(f\"epoch {epoch}\")\n",
        "            start = i*batch_size\n",
        "            stop = i*batch_size+batch_size\n",
        "\n",
        "            key, *bkeys = jax.random.split(key, batch_size+1)\n",
        "            loss, model, opt_state = make_step(model, x_train[start:stop], y_train[start:stop], opt_state, bkeys)\n",
        "            loss = loss.item()\n",
        "            bar.set_postfix(loss=loss)\n",
        "\n",
        "        ### compute metrics ###\n",
        "\n",
        "        metrics = {\"loss\":[],\n",
        "                  \"accuracy\":[]}\n",
        "\n",
        "        for i in range(val_steps):\n",
        "          start = i*batch_size\n",
        "          stop = i*batch_size+batch_size\n",
        "\n",
        "          key, *bkeys = jax.random.split(key, batch_size+1)\n",
        "          l = compute_metrics(model, x_test[start:stop], y_test[start:stop], bkeys)\n",
        "\n",
        "          metrics[\"loss\"].append(l[0])\n",
        "          metrics[\"accuracy\"].append(l[1])\n",
        "\n",
        "        print(\"loss: \" + str(jnp.mean(jnp.array(metrics[\"loss\"]))) + \", accuracy: \" + str(100*jnp.mean(jnp.array(metrics[\"accuracy\"]))) + \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p-O5zizjcIuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b060ba-c4cc-4dbd-c1c7-de49f038a0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 0: 100%|██████████| 468/468 [00:26<00:00, 17.81it/s, loss=0.0538]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.15498702, accuracy: 95.44271%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1: 100%|██████████| 468/468 [00:09<00:00, 47.58it/s, loss=0.0349]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.09950211, accuracy: 96.905045%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2: 100%|██████████| 468/468 [00:09<00:00, 48.25it/s, loss=0.0543]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.08405958, accuracy: 97.3758%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3: 100%|██████████| 468/468 [00:09<00:00, 47.93it/s, loss=0.0141]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.07233128, accuracy: 97.79648%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4: 100%|██████████| 468/468 [00:09<00:00, 47.77it/s, loss=0.0262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.06449932, accuracy: 98.02684%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5: 100%|██████████| 468/468 [00:09<00:00, 47.57it/s, loss=0.0202]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.05718883, accuracy: 98.20713%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6: 100%|██████████| 468/468 [00:10<00:00, 46.33it/s, loss=0.0247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.05789528, accuracy: 98.02684%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7: 100%|██████████| 468/468 [00:09<00:00, 47.22it/s, loss=0.0335]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.052895613, accuracy: 98.227165%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8: 100%|██████████| 468/468 [00:09<00:00, 47.36it/s, loss=0.015]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.05443692, accuracy: 98.31731%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9: 100%|██████████| 468/468 [00:09<00:00, 47.43it/s, loss=0.0278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.04910239, accuracy: 98.507614%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 10: 100%|██████████| 468/468 [00:09<00:00, 47.55it/s, loss=0.0156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.047235426, accuracy: 98.4375%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 11: 100%|██████████| 468/468 [00:09<00:00, 47.31it/s, loss=0.0119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.043852136, accuracy: 98.58774%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 12: 100%|██████████| 468/468 [00:09<00:00, 47.04it/s, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.043277003, accuracy: 98.547676%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 13: 100%|██████████| 468/468 [00:09<00:00, 47.25it/s, loss=0.0088]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.04302097, accuracy: 98.64784%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 14: 100%|██████████| 468/468 [00:09<00:00, 47.27it/s, loss=0.019]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.040528145, accuracy: 98.63782%\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "simple mnist convnet",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}